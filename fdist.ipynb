{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a5ac51c-c798-42ef-a322-2e29fbfe530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from spacy.tokens import DocBin\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "\n",
    "available_processors = os.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbad9c4e-f346-4d6b-8c41-0e5c7c930dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_clean(doc, remove_stopwords=True):\n",
    "    cleaned_doc = list()\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        elif remove_stopwords == True and token.is_stop:\n",
    "            continue\n",
    "        elif token.pos_ == \"SPACE\":\n",
    "            continue\n",
    "        else:\n",
    "            cleaned_doc.append(token)\n",
    "    return cleaned_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf9e4d2-2def-45e5-848d-faf753d4f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docbin_from_tg_record_id(x, d2db):\n",
    "    try:\n",
    "        dt = d2db[x][\"docbin\"]\n",
    "        return dt\n",
    "        \n",
    "    except:\n",
    "        dt = None\n",
    "        return dt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5811eb18-5720-4797-b994-9f80c500901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docbin_line_from_tg_record_id(x, d2db):\n",
    "    try:\n",
    "        dt = d2db[x][\"line\"]\n",
    "        return dt\n",
    "        \n",
    "    except:\n",
    "        dt = None\n",
    "        return dt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95e5206-b5b8-469d-888d-436033697c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_lines_tg(df, doc2docbin_path):\n",
    "    d2db = json.load(open(doc2docbin_path, 'r'))\n",
    "    df['docbin'] = df.record_id.apply(lambda x: get_docbin_from_tg_record_id(x, d2db))\n",
    "    df['docbin_line'] = df.record_id.apply(lambda x: get_docbin_line_from_tg_record_id(x, d2db))\n",
    "    \n",
    "    grouped = df.groupby('docbin')['docbin_line'].apply(lambda x: list(set(x)))\n",
    "    sample = [(docbin, lines) for docbin, lines in grouped.items()]\n",
    "    print(f\"Generated sample with {len(sample)} items\")\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ba1551-d773-4806-bf0a-97194c082d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docbin_counter(docbin, query_docs, nlp, remove_stopwords = True, entities = False):\n",
    "    import spacy\n",
    "    nlp = spacy.load('nl_core_news_sm')\n",
    "    \n",
    "    docbin_subtotal = Counter()\n",
    "    db = DocBin().from_disk(docbin)\n",
    "    docs = list(db.get_docs(nlp.vocab))\n",
    "    \n",
    "    print('processing docbin_counter')\n",
    "    if entities == True:\n",
    "        for line in query_docs:\n",
    "            doc = docs[int(line)]\n",
    "            doc_counter = Counter([(token[0], token[1]) for token in doc_clean_entities(doc, remove_stopwords = remove_stopwords)])\n",
    "            docbin_subtotal.update(doc_counter)\n",
    "            \n",
    "    elif entities == False:\n",
    "        for line in query_docs:\n",
    "            doc = docs[int(line)]\n",
    "            doc_counter = Counter([(token.lemma_, token.pos_) for token in doc_clean(doc, remove_stopwords=remove_stopwords)])\n",
    "            docbin_subtotal.update(doc_counter)\n",
    "            #print(f'docbin subtotal = {docbin_subtotal}') PRINTS (TERM : LABEL) : COUNT\n",
    "    return docbin_subtotal\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a190bbbf-3aa6-41b5-b4a6-dd0b071d6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def docbin_counter_onecore(sample, remove_stopwords = True, entities = False, docbin_folder = \"./r_TheRedPill_docbins/\", file_prefix = \"r_TheRedPill\", workers = available_processors):\n",
    "    counters = None\n",
    "    \n",
    "    args = [(docbin_folder + \"/\" + file_prefix + \"_docbin_\" + str(int(docbin)) + \".db\", \n",
    "             query_docs, \n",
    "             remove_stopwords, \n",
    "             entities\n",
    "            ) for docbin, query_docs in sample]\n",
    "\n",
    "    for a in args:\n",
    "        counters = docbin_counter(a[0],a[1],spacy.load('nl_core_news_sm') ,a[2],a[3])\n",
    "        break\n",
    "    \n",
    "    total = Counter()\n",
    "    \n",
    "    for counter in counters:\n",
    "        total.update(counter)\n",
    "        \n",
    "    \n",
    "    return counters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d58ceae-e328-4e53-9bd7-8943c2462668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdist2table(fdist, savename = \"./heads_of_state_fdist.xlsx\"):\n",
    "    \n",
    "    keys = list(fdist.keys())\n",
    "    records = [(key[0], key[1], fdist[key]) for key in keys]\n",
    "    \n",
    "    tb = pd.DataFrame.from_records(records, columns = [\"word\", \"label\", \"count\"])\n",
    "    tb = tb.loc[(tb[\"label\"] != \"SPACE\") & (tb[\"label\"] != \"PUNCT\")] # taking out some unnecessary parts of speech\n",
    "    tb.to_excel(savename, index = False, engine = 'xlsxwriter')\n",
    "    print(\"Frequency distribution saved!\")\n",
    "    return tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48c3f97-78b2-4c4d-a9de-e5a0a30f945a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sample with 5 items\n",
      "Processing FVDNL_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of FVDNL_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 5 items\n",
      "Processing Gerrit_Brendel_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of Gerrit_Brendel_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 7 items\n",
      "Processing InfodefenseNED_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of InfodefenseNED_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 24 items\n",
      "Processing Mariba2puntnul_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of Mariba2puntnul_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 5 items\n",
      "Processing NieuwsvoorNederlanders_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of NieuwsvoorNederlanders_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 4 items\n",
      "Processing Openbaringen_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of Openbaringen_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 49 items\n",
      "Processing RinusVerhagen_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of RinusVerhagen_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 12 items\n",
      "Processing SoulflixMedia_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of SoulflixMedia_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 61 items\n",
      "Processing bataafsemossel_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of bataafsemossel_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 17 items\n",
      "Processing berichten_uit_donbass_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of berichten_uit_donbass_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 5 items\n",
      "Processing blckbxtv_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of blckbxtv_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 22 items\n",
      "Processing carelvdf_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of carelvdf_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 122 items\n",
      "Processing deguldenmiddenweg_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of deguldenmiddenweg_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 12 items\n",
      "Processing derdekamer_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of derdekamer_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 11 items\n",
      "Processing ditishetnieuws_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of ditishetnieuws_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 51 items\n",
      "Processing european_dissident_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of european_dissident_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 25 items\n",
      "Processing gek_genoeg_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of gek_genoeg_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 2 items\n",
      "Processing gezond_verstand_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of gezond_verstand_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 9 items\n",
      "Processing hetkantelpunt_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of hetkantelpunt_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 8 items\n",
      "Processing hetkloptniet_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of hetkloptniet_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 5 items\n",
      "Processing jolandavlaskamp_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of jolandavlaskamp_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 65 items\n",
      "Processing maddogholland_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of maddogholland_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 3 items\n",
      "Processing ministerievanwaarheid_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of ministerievanwaarheid_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 11 items\n",
      "Processing ninefornews_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of ninefornews_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 6 items\n",
      "Processing talktomem_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of talktomem_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 22 items\n",
      "Processing truthned_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of truthned_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 9 items\n",
      "Processing verbodenfacebookdingen_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of verbodenfacebookdingen_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 6 items\n",
      "Processing vmBeeld_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of vmBeeld_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 16 items\n",
      "Processing vmGeluid_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of vmGeluid_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 34 items\n",
      "Processing warekracht_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of warekracht_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n",
      "Generated sample with 15 items\n",
      "Processing wietsenijboer_docbins. Please wait as this may take a while...\n",
      "processing docbin_counter\n",
      "Frequency distribution of wietsenijboer_docbins created.\n",
      "Frequency distribution saved!\n",
      "Dataframe Preview (count >= 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filepath = 'S:\\\\ERP Raw Data\\\\pien\\\\THESIS\\\\docbins'\n",
    "filepath_parquets = 'S:\\\\ERP Raw Data\\\\pien\\\\THESIS\\\\parquets'\n",
    "filepath_fdists = 'S:\\\\ERP Raw Data\\\\pien\\\\THESIS\\\\fdists'\n",
    "\n",
    "for file in os.listdir(filepath):\n",
    "\n",
    "    file_base = file.removesuffix('_docbins')\n",
    "    \n",
    "    #paths\n",
    "    docbin_folder = os.path.join(filepath, file)\n",
    "    d2db_path = os.path.join(docbin_folder, f\"{file_base}_doc2docbin.json\")\n",
    "    parq_direct = os.path.join(filepath_parquets, f'{file_base}.pqt')\n",
    "    \n",
    "    smpl = get_sample_lines_tg(pd.read_parquet(parq_direct), d2db_path)\n",
    "    num_workers = os.cpu_count()\n",
    "        \n",
    "    print(f\"Processing {file}. Please wait as this may take a while...\")\n",
    "    fdist = docbin_counter_onecore( #docbin_counter_multicore\n",
    "            smpl,\n",
    "            remove_stopwords = True,\n",
    "            entities = False,\n",
    "            docbin_folder = docbin_folder,\n",
    "            file_prefix = file_base,\n",
    "            workers = num_workers\n",
    "        )\n",
    "\n",
    "    print(f'Frequency distribution of {file} created.')\n",
    "        # logic to save files\n",
    "    \n",
    "\n",
    "    new_folder = os.path.join(filepath_fdists, f'{file_base}_fdist')\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "    savename = f'frequency_distribution_{file_base}'\n",
    "\n",
    "# save a pickle (with .fdist extension) and an excel file\n",
    "    pkl_of = os.path.join(new_folder, savename + \".fdist\")\n",
    "    xls_of = os.path.join(new_folder, savename + \".xlsx\")\n",
    "\n",
    "    # save fdist using pickle\n",
    "    with open(pkl_of, 'wb') as fdist_out:\n",
    "        pickle.dump(fdist, fdist_out)\n",
    "    # save fdist using excel\n",
    "    fdist_df = fdist2table(fdist, xls_of)\n",
    "\n",
    "    # create preview for user\n",
    "    fdist_df = fdist_df[fdist_df[\"count\"] >= 50]\n",
    "    print(\"Dataframe Preview (count >= 50)\")\n",
    "    print(fdist_df)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
