{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369cf107-e7dd-4b0e-a1e2-78a61a030530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import os\n",
    "import pandas as pd\n",
    "from stqdm import stqdm as tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb3bcd9-2b7b-4800-b71f-3f228498b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_parquet_telegram_text_column(db, batch_size=1000, columns=[\"message_text\", \"record_id\"]):\n",
    "    \n",
    "    batch = []\n",
    "    \n",
    "    for record_batch in db.to_batches(columns=columns, batch_size = batch_size):\n",
    "        \n",
    "        col_message_text = record_batch.column(0)\n",
    "        col_record_id = record_batch.column(1)\n",
    "\n",
    "        for text, record_id in zip(col_message_text, col_record_id):\n",
    "            batch.append((text.as_py(), record_id.as_py()))\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "    if batch:\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8c2357-a939-48a5-bfe9-13ee2229a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_telegram_text_main(nlp, parquet_file, docbin_folder = \"./myfolder\", file_prefix = \"myname\", workers = 1, batch_size = 1000):\n",
    "\n",
    "    doc2docbin = dict()\n",
    "\n",
    "    \n",
    "    db = ds.dataset(parquet_file, format = \"parquet\")\n",
    "    n_batches = db.count_rows() // batch_size + 1\n",
    "\n",
    "    docs = stream_parquet_telegram_text_column(db, batch_size = batch_size, columns = [\"message_text\", \"record_id\"])\n",
    "\n",
    "    if not os.path.exists(docbin_folder):\n",
    "        os.mkdir(docbin_folder)\n",
    "\n",
    "    print(\"Processing docbins...\")\n",
    "    for i, batch in enumerate(docs):\n",
    "        before = len(batch)\n",
    "        batch = [(text, rid) for (text, rid) in batch if text is not None]\n",
    "        after = len(batch)\n",
    "        if before != after:\n",
    "            print(f\"Dropped {before - after} None records in batch {i}\")\n",
    "\n",
    "        doc_bin = DocBin()\n",
    "        docbin_name = f\"{docbin_folder}/{file_prefix}_docbin_{i}.db\"\n",
    "        \n",
    "        for j, (doc, record_id) in enumerate(nlp.pipe(batch, n_process = workers, batch_size = batch_size, as_tuples=True)):\n",
    "            \n",
    "            doc2docbin[record_id] = {\n",
    "                \"docbin\" : i,\n",
    "                \"line\": j\n",
    "            }\n",
    "            \n",
    "            doc_bin.add(doc)\n",
    "\n",
    "        doc_bin.to_disk(docbin_name)\n",
    "        # print(f\"Docbin: {docbin_name} saved.\")\n",
    "\n",
    "    print(\"Saving index...\")\n",
    "\n",
    "    json_path = f\"{docbin_folder}/{file_prefix}_doc2docbin.json\"\n",
    "\n",
    "    with open(json_path, \"w\") as d2db:\n",
    "        json.dump(doc2docbin, d2db, indent = 4)\n",
    "\n",
    "    print(\"Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea02c0e-3346-4498-bf7d-210a28820582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing bataafsemossel docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing berichten_uit_donbass docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing blckbxtv docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing carelvdf docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing deguldenmiddenweg docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing derdekamer docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing ditishetnieuws docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing european_dissident docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing gek_genoeg docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing gezond_verstand docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing hetkantelpunt docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing hetkloptniet docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing jolandavlaskamp docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing maddogholland docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing ministerievanwaarheid docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing ninefornews docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing talktomem docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing truthned docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing verbodenfacebookdingen docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing vmBeeld docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing vmGeluid docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing warekracht docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n",
      "processing wietsenijboer docbins...\n",
      "Processing docbins...\n",
      "Saving index...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "filepath_gen = 'S:\\\\ERP Raw Data\\\\pien\\\\THESIS'\n",
    "filepath_parq = 'S:\\\\ERP Raw Data\\\\pien\\\\THESIS\\\\parquets'\n",
    "\n",
    "nlp = spacy.load('nl_core_news_sm')\n",
    "num_workers = os.cpu_count()    \n",
    "    \n",
    "for file in os.listdir(filepath_parq):\n",
    "    name_base = file.removesuffix('.pqt')\n",
    "    batch_size = 1000\n",
    "    print(f'processing {name_base} docbins...')\n",
    "\n",
    "    process_telegram_text_main(\n",
    "        nlp=nlp, \n",
    "        parquet_file = os.path.join(filepath_parq, file),\n",
    "        docbin_folder = f'{name_base}_docbins',\n",
    "        file_prefix = f'{name_base}', \n",
    "        workers = num_workers,\n",
    "        batch_size = batch_size\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
